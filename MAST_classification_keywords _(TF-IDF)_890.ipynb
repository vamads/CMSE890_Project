{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, datasets, preprocessing, svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.read_parquet('s2orc_mast_corpus_25oct2022.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mast_complete_clean_original = pd.read_parquet('s2orc_mast_labels_25oct2022.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>included</th>\n",
       "      <th>bibcode</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>mission</th>\n",
       "      <th>paper_type</th>\n",
       "      <th>arxiv</th>\n",
       "      <th>mast</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "      <td>8118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14813</td>\n",
       "      <td>14813</td>\n",
       "      <td>14813</td>\n",
       "      <td>14813</td>\n",
       "      <td>0</td>\n",
       "      <td>14813</td>\n",
       "      <td>14813</td>\n",
       "      <td>14813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           included  bibcode  publication_date  mission  paper_type  arxiv  \\\n",
       "label_idx                                                                    \n",
       "0              8118     8118              8118     8118        8118   8118   \n",
       "1             14813    14813             14813    14813           0  14813   \n",
       "\n",
       "            mast   year  \n",
       "label_idx                \n",
       "0           8118   8118  \n",
       "1          14813  14813  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mast_complete_clean_original.groupby('label_idx').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'MENTION', 'SCIENCE', 'DATA_INFLUENCED', 'SUPERMENTION',\n",
       "       'UNRESOLVED_GREY', 'ENGINEERING', 'INSTRUMENT'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mast_complete_clean_original.paper_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize data by sentences \n",
    "corpus=[]\n",
    "for i in corpus_df['clean_text']:\n",
    "    add = sent_tokenize(i)\n",
    "    corpus.append(add)\n",
    "corpus_df['sentences']=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['MAST', 'GALEX', 'Galaxy Evolution Explorer', 'FUSE', 'Far Ultraviolet Spectroscopic Explorer', 'IUE', 'International Ultraviolet Explorer', 'EUVE', 'Extreme Ultraviolet Explorer', 'ORFEUS', 'Orbiting Retrievable Far and Extreme Ultraviolet Spectrometers', 'BEFS', 'Berkeley Extreme and Far-UV Spectrometer', 'Berkeley Spectrometer', 'IMAPS', 'Interstellar Medium Absorption Profile Spectrograph', 'TUES', 'Tubingen Ultraviolet Echelle Spectrometer', 'UIT', 'Ultraviolet Imaging Telescope', 'HUT', 'Hopkins Ultraviolet Telescope', 'WUPPE', 'Wisconsin Ultraviolet Photo-Polarimeter Experiment', 'Copernicus', 'OAO-3', 'Kepler', 'AIDA', 'K2', 'TESS', 'Transiting Exoplanet Survey Satellite', 'K2', 'KTWOCANDELS', 'PANSTARRS', 'Pan-STARRS', 'PAN STARRS', '10.17909', 'PanSTARRS-1', 'Pan-STARRS-1', 'PanSTARRS1', 'Pan-STARRS1', 'PS1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp=re.compile('|'.join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pull out specified sentences\n",
    "def relevant_sentences(before,after):\n",
    "    sentences_HST=[]\n",
    "    for sentences in corpus_df['sentences']:\n",
    "        sentences_HST.append([])\n",
    "        for j,y in enumerate(sentences):\n",
    "            match=regexp.findall(y)\n",
    "            if len(match)>=1: #or len(match2)>=1:\n",
    "                sentences_HST[-1].append(y)\n",
    "                if j>before and j<(len(sentences)-after):\n",
    "                    sentences_HST[-1].extend(sentences[j-before:j+after])\n",
    "        sentences_HST[-1]=list(set(sentences_HST[-1]))\n",
    "    return sentences_HST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_keywords = relevant_sentences(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df['sentences_keywords'] = sentences_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check length \n",
    "corpus = []\n",
    "for i in corpus_df['sentences_keywords']:\n",
    "    add = len(i)\n",
    "    corpus.append(add)\n",
    "corpus_df['len_MAST']=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = corpus_df['len_MAST'] >= 1\n",
    "sentences_df = corpus_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1534084/3784890861.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentences_df['joined'] = corpus\n"
     ]
    }
   ],
   "source": [
    "#join all sentences per paper to use in tfidf\n",
    "corpus=[]\n",
    "for i,j in enumerate(sentences_df['sentences_keywords']):\n",
    "    if len(j) >= 1:\n",
    "        add = ''.join(j)#''.join(j)\n",
    "        corpus.append(add)\n",
    "    else:\n",
    "        add = sentences_df['clean_text'][i]\n",
    "        corpus.append(add)\n",
    "sentences_df['joined'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences_df = sentences_df[sentences_df['len_MAST'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences_df.groupby('label').count()[sentences_df['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1534084/3707832172.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['label'] = sentences_df.label\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = sentences_df[['clean_text','joined', 'label']]\n",
    "cleaned_df['label'] = sentences_df.label\n",
    "#cleaned_df.set_index('arxiv_id',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (689680090.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1534084/689680090.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    random_state = 200a\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#test with random sample\n",
    "random_state = 200a\n",
    "holdout = cleaned_df.sample(frac = 0.2, random_state = random_state, axis = 0)\n",
    "cleaned_df = cleaned_df.loc[~cleaned_df.index.isin(holdout.index)]\n",
    "mast_complete_clean = mast_complete_clean_original.loc[mast_complete_clean_original.index.isin(cleaned_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_df.to_hdf('MAST_sentences.h5', key = 'cleaned_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "tfidf_vector = TfidfVectorizer(min_df = 0.001, max_df = 0.999,ngram_range = (1,2))\n",
    "tfidf_vector.fit(cleaned_df['joined'])\n",
    "X_tfidf = tfidf_vector.transform(cleaned_df['joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tfidf = TfidfVectorizer(min_df = 0.001, max_df = 0.999,ngram_range = (1,2))\n",
    "full_tfidf.fit(cleaned_df['clean_text'])\n",
    "full_tf = full_tfidf.transform(cleaned_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mast_complete_feat = X_tfidf\n",
    "mast_complete_clean_reduced = cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rf_feat_train, rf_feat_test, \n",
    " rf_label_train, rf_label_test,) = train_test_split(\n",
    "    mast_complete_feat, mast_complete_clean_reduced.label.values, \n",
    "    train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(X_tfidf)\n",
    "full_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(full_tf)\n",
    "sentences_embedded.shape,full_embedded.shape         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_full = pd.DataFrame(full_embedded, columns = ['D0','D1'])\n",
    "TSNE_full['label'] = mast_complete_clean_reduced['label'].to_numpy()\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=TSNE_full.iloc[:,0], y=TSNE_full.iloc[:,1],\n",
    "    hue = TSNE_full['label'],\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_df = pd.DataFrame(sentences_embedded, columns = ['D0','D1'])\n",
    "TSNE_df['label'] = mast_complete_clean_reduced['label'].to_numpy()\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=TSNE_df.iloc[:,0], y=TSNE_df.iloc[:,1],\n",
    "    hue = TSNE_df['label'],\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    legend=\"full\",\n",
    "    alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics, datasets, preprocessing, svm\n",
    "svm_class = svm.SVC(random_state = random_state, class_weight = {0:.6, 1:.4})\n",
    "#MLP_class=MLPClassifier(solver = 'adam', activation = 'relu', learning_rate = 'adaptive')\n",
    "#rf_class = CalibratedClassifierCV(RandomForestClassifier(n_estimators=500,verbose=1, n_jobs=4, min_samples_leaf=10, ))\n",
    "svm_class.fit(rf_feat_train, rf_label_train)\n",
    "#MLP_class.fit(rf_feat_train, rf_label_train)\n",
    "#rf_class.fit(rf_feat_train, rf_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#predict = svm_class.predict(rf_feat_test)\n",
    "predict = svm_class.predict(rf_feat_test)\n",
    "metrics.accuracy_score(predict, rf_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab notebook\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ConfusionMatrixDisplay.from_estimator(svm_class, rf_feat_test, rf_label_test, normalize='true', ax = ax)\n",
    "fig.gca().set_xticklabels(['MAST Data','MAST Reference'],fontsize=20)\n",
    "fig.gca().set_yticklabels(['MAST Data','MAST Reference'],fontsize=20, rotation='vertical', verticalalignment='center')\n",
    "fig.gca().yaxis.label.set_size(25)\n",
    "fig.gca().xaxis.label.set_size(25)\n",
    "for t in fig.gca().texts:\n",
    "    t.set_fontsize(40)\n",
    "fig.savefig('mast_confusion.pdf',format = 'pdf', dpi = 1000,transparent = False, bbox_inches = \"tight\", pad_inches = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab notebook\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ConfusionMatrixDisplay.from_estimator(svm_class, rf_feat_test, rf_label_test, normalize='true', ax = ax)\n",
    "fig.gca().set_xticklabels(['MAST Data','MAST Reference'],fontsize=20)\n",
    "fig.gca().set_yticklabels(['MAST Data','MAST Reference'],fontsize=20, rotation='vertical', verticalalignment='center')\n",
    "fig.gca().yaxis.label.set_size(25)\n",
    "fig.gca().xaxis.label.set_size(25)\n",
    "for t in fig.gca().texts:\n",
    "    t.set_fontsize(40)\n",
    "fig.savefig('mast_confusion.pdf',format = 'pdf', dpi = 1000,transparent = False, bbox_inches = \"tight\", pad_inches = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(rf_label_test, predict, average='macro'))\n",
    "\n",
    "print(f1_score(rf_label_test, predict, average='micro'))\n",
    "\n",
    "print(f1_score(rf_label_test, predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(rf_label_test, predict)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='example estimator')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "y_pred = svm_class.decision_function(rf_feat_test)\n",
    "RocCurveDisplay.from_predictions(rf_label_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(svm_class, rf_feat_test, rf_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,12), tight_layout=True)\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "RocCurveDisplay.from_estimator(svm_class, rf_feat_test, rf_label_test, pos_label = 0, ax = ax)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.ylabel('False Positive Rate')\n",
    "fig.gca().yaxis.label.set_size(40)\n",
    "fig.gca().xaxis.label.set_size(40)\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "for t in fig.gca().texts:\n",
    "    t.set_fontsize(32)\n",
    "fig.savefig('mast_roc.pdf',format = 'pdf', dpi = 1000,transparent = False, bbox_inches = \"tight\", pad_inches = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svm_class, rf_feat_train, rf_label_train, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "recall_score(rf_label_test, predict, average = 'weighted'), precision_score(rf_label_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Data Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_tfidf = tfidf_vector.transform(holdout['joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predict = svm_class.predict(holdout_tfidf)\n",
    "metrics.accuracy_score(holdout_predict,holdout.label.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df=pd.DataFrame(columns=('Doc2Vec','TF-IDF'),data=[[0.761,0.810],[0.853,0.876],[0.838,0.860]])\n",
    "# vectorization=pd.Series(['Random Forest','Support Vector Machine', 'Deep Neural Network'])\n",
    "# df=df.set_index(vectorization)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_tokens = pd.DataFrame(\n",
    "#     data=svm_class.coef_[0].todense().T,\n",
    "#     index=tfidf_vector.get_feature_names(),\n",
    "#     columns=['coefficient0']\n",
    "# ).sort_values(by = 'coefficient0',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=df.plot(rot=0,kind='bar',figsize=(20, 10),fontsize=30)\n",
    "# fig.legend(loc=0,prop={'size': 20})\n",
    "# #fig.set_title('Accuracy for Classification Techniques')\n",
    "# fig.set_ylabel(\"Accuracy\")\n",
    "# fig.set_xlabel(\"Classifiers\")\n",
    "# fig.title.set_size(50)\n",
    "# fig.xaxis.label.set_size(25)\n",
    "# fig.yaxis.label.set_size(25)\n",
    "# fig.figure.savefig('hst_bar.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepthought",
   "language": "python",
   "name": "deepthought"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
